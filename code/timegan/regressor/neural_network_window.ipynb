{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n",
    "import pandas as pd\n",
    "from ydata_synthetic.preprocessing.timeseries.utils import real_data_loading\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fatNum(n):\n",
    "    i = n // 9\n",
    "    j = (n % 9) // 3\n",
    "    k = ((n % 9) % 3) \n",
    "    \n",
    "    return i,j,k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First implement a simple RNN model for prediction\n",
    "def RNN_regression(units):\n",
    "    opt = Adam(name='AdamOpt')\n",
    "    loss = MeanAbsoluteError(name='MAE')\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=units,\n",
    "                  name=f'RNN_1'))\n",
    "    model.add(Dense(units=14,\n",
    "                    activation='sigmoid',\n",
    "                    name='OUT'))\n",
    "    model.compile(optimizer=opt, loss=loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumFeatureMetricsOfModels(models, data_metrics):\n",
    "    count32 = np.zeros(len(models))\n",
    "    count64 = np.zeros(len(models))\n",
    "\n",
    "    for i in range(len(models)): \n",
    "            count32[i] = sum(data_metrics[0,i,:])\n",
    "            count64[i] = sum(data_metrics[1,i,:])\n",
    "            \n",
    "    return count32, count64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeaturesBestMetricsOfModels(models, data_metrics):\n",
    "    count32, count64 = sumFeatureMetricsOfModels(models, data_metrics)\n",
    "    \n",
    "    print(count32)\n",
    "    print(count64)\n",
    "    \n",
    "    index = np.where(count32 == count32.min())[0][0]\n",
    "    i, j, k = fatNum(index)\n",
    "    model = 'so_seqlen_' + str((50*(i) + 50)) + '_hidim_'+str(20*(j)+20) + '_batch_'+str(28*(k)+100)+'.pkl'\n",
    "    print('bestmodel_int32:' + model)\n",
    "    best_32 = models.get(model)[0]\n",
    "    \n",
    "    index = np.where(count64 == count64.min())[0][0]\n",
    "    i, j, k = fatNum(index)\n",
    "    model = 'so_seqlen_' + str((50*(i) + 50)) + '_hidim_'+str(20*(j)+20) + '_batch_'+str(28*(k)+100)+'.pkl'\n",
    "    print('bestmodel_int64:' + model)\n",
    "    best_64 = models.get(model)[0]\n",
    "    \n",
    "    \n",
    "    index = np.where(count32 == count32.max())[0][0]\n",
    "    i, j, k = fatNum(index)\n",
    "    model = 'so_seqlen_' + str((50*(i) + 50)) + '_hidim_'+str(20*(j)+20) + '_batch_'+str(28*(k)+100)+'.pkl'\n",
    "    print('bestmodel_int32:' + model)\n",
    "    worst_32 = models.get(model)[0]\n",
    "    \n",
    "    index = np.where(count64 == count64.max())[0][0]\n",
    "    i, j, k = fatNum(index)\n",
    "    model = 'so_seqlen_' + str((50*(i) + 50)) + '_hidim_'+str(20*(j)+20) + '_batch_'+str(28*(k)+100)+'.pkl'\n",
    "    print('bestmodel_int64:' + model)\n",
    "    worst_64 = models.get(model)[0]\n",
    "    \n",
    "    return best_32, worst_32, best_64, worst_64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 2400\n",
    "seq_len = 50\n",
    "\n",
    "realdata_config = 'real9_50_3600_norm'\n",
    "models_config = 'models9_50_3600_norm'\n",
    "metrics_config= 'metrics9_50_3600_norm'\n",
    "\n",
    "num_cols = ['enq_qdepth1','deq_timedelta1', 'deq_qdepth1',\n",
    "            ' enq_qdepth2', ' deq_timedelta2', ' deq_qdepth2',\n",
    "            'enq_qdepth3', 'deq_timedelta3', 'deq_qdepth3',\n",
    "            'Buffer', 'ReportedBitrate', 'FPS', 'CalcBitrate',\n",
    "            'q_size'] \n",
    "cat_cols = ['Resolution']\n",
    "\n",
    "data = np.zeros(2*9*len(num_cols)).reshape(2,9,len(num_cols))\n",
    "\n",
    "with open('../saved_objects/' + metrics_config + '.pkl', 'rb') as file:\n",
    "        # Load the object from the file\n",
    "        data = pickle.load(file)\n",
    "        \n",
    "with open('../saved_objects/' + models_config + '.pkl', 'rb') as file:\n",
    "        # Load the object from the file\n",
    "        models = pickle.load(file)\n",
    "\n",
    "with open('../saved_objects/' + realdata_config + '.pkl', 'rb') as file:\n",
    "        # Load the object from the file\n",
    "        real_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_32 = real_data[0]\n",
    "real_64 = real_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.55606701 1.07867633 2.49299797 5.54779726 0.43967091 1.30029685\n",
      " 1.77256908 3.88010907 3.10767045]\n",
      "[2.06309326 1.72980215 0.65540989 1.51944118 1.70368999 2.74427812\n",
      " 1.69580751 1.28739328 0.337264  ]\n",
      "bestmodel_int32:so_seqlen_50_hidim_40_batch_128.pkl\n",
      "bestmodel_int64:so_seqlen_50_hidim_60_batch_156.pkl\n",
      "bestmodel_int32:so_seqlen_50_hidim_40_batch_100.pkl\n",
      "bestmodel_int64:so_seqlen_50_hidim_40_batch_156.pkl\n"
     ]
    }
   ],
   "source": [
    "best_modelsum_32, worst_modelsum_32, best_modelsum_64, worst_modelsum_64 = getFeaturesBestMetricsOfModels(models, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_32 = real_data_loading(real_32, seq_len=seq_len)\n",
    "real_64 = real_data_loading(real_64, seq_len=seq_len)\n",
    "\n",
    "best_modelsum_32 = real_data_loading(best_modelsum_32, seq_len=seq_len)\n",
    "worst_modelsum_32 = real_data_loading(worst_modelsum_32, seq_len=seq_len)\n",
    "best_modelsum_64 = real_data_loading(best_modelsum_64, seq_len=seq_len)\n",
    "worst_modelsum_64 = real_data_loading(worst_modelsum_64, seq_len=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the dataset for the regression model\n",
    "real_data = np.asarray(real_32)\n",
    "synth_data = np.asarray(worst_modelsum_32)\n",
    "\n",
    "synth_data = synth_data[:len(real_32)]\n",
    "n_events = len(real_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(real_data))\n",
    "print(type(synth_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic X train: (1782, 49, 14)\n",
      "Real X train: (1782, 49, 14)\n",
      "Synthetic y train: (1782, 14)\n",
      "Real y train: (1782, 14)\n",
      "Real X test: (594, 49, 14)\n",
      "Real y test: (594, 14)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Split data on train and test\n",
    "idx = np.arange(n_events)\n",
    "n_train = int(.75*n_events)\n",
    "train_idx = idx[:n_train]\n",
    "test_idx = idx[n_train:]\n",
    "\n",
    "#Define the X for synthetic and real data\n",
    "X_real_train = real_data[train_idx, :seq_len-1, 0:14]\n",
    "X_synth_train = synth_data[train_idx, :seq_len-1, 0:14]\n",
    "\n",
    "X_real_test = real_data[test_idx, :seq_len-1, 0:14]\n",
    "\n",
    "\n",
    "#Define the y for synthetic and real datasets\n",
    "y_real_test = real_data[test_idx, -1, 0:14]\n",
    "y_real_train = real_data[train_idx, -1, 0:14]\n",
    "\n",
    "y_synth_train = synth_data[train_idx, -1, 0:14]\n",
    "\n",
    "print('Synthetic X train: {}'.format(X_synth_train.shape))\n",
    "print('Real X train: {}'.format(X_real_train.shape))\n",
    "\n",
    "print('Synthetic y train: {}'.format(y_synth_train.shape))\n",
    "print('Real y train: {}'.format(y_real_train.shape))\n",
    "\n",
    "print('Real X test: {}'.format(X_real_test.shape))\n",
    "print('Real y test: {}'.format(y_real_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 2s 48ms/step - loss: 0.3878 - val_loss: 0.3799\n",
      "Epoch 2/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3738 - val_loss: 0.3657\n",
      "Epoch 3/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3596 - val_loss: 0.3506\n",
      "Epoch 4/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3434 - val_loss: 0.3322\n",
      "Epoch 5/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3227 - val_loss: 0.3074\n",
      "Epoch 6/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2948 - val_loss: 0.2765\n",
      "Epoch 7/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2648 - val_loss: 0.2479\n",
      "Epoch 8/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2378 - val_loss: 0.2230\n",
      "Epoch 9/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2147 - val_loss: 0.2019\n",
      "Epoch 10/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1954 - val_loss: 0.1841\n",
      "Epoch 11/200\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1792 - val_loss: 0.1696\n",
      "Epoch 12/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1659 - val_loss: 0.1576\n",
      "Epoch 13/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1550 - val_loss: 0.1477\n",
      "Epoch 14/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1459 - val_loss: 0.1395\n",
      "Epoch 15/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1384 - val_loss: 0.1327\n",
      "Epoch 16/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1321 - val_loss: 0.1269\n",
      "Epoch 17/200\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1267 - val_loss: 0.1220\n",
      "Epoch 18/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1222 - val_loss: 0.1178\n",
      "Epoch 19/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1182 - val_loss: 0.1142\n",
      "Epoch 20/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1148 - val_loss: 0.1110\n",
      "Epoch 21/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1118 - val_loss: 0.1082\n",
      "Epoch 22/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1091 - val_loss: 0.1057\n",
      "Epoch 23/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1067 - val_loss: 0.1034\n",
      "Epoch 24/200\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1046 - val_loss: 0.1014\n",
      "Epoch 25/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1026 - val_loss: 0.0995\n",
      "Epoch 26/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1009 - val_loss: 0.0979\n",
      "Epoch 27/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0994 - val_loss: 0.0964\n",
      "Epoch 28/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0980 - val_loss: 0.0951\n",
      "Epoch 29/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0967 - val_loss: 0.0939\n",
      "Epoch 30/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0955 - val_loss: 0.0928\n",
      "Epoch 31/200\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0944 - val_loss: 0.0917\n",
      "Epoch 32/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0934 - val_loss: 0.0908\n",
      "Epoch 33/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0925 - val_loss: 0.0898\n",
      "Epoch 34/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0916 - val_loss: 0.0890\n",
      "Epoch 35/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0908 - val_loss: 0.0883\n",
      "Epoch 36/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0901 - val_loss: 0.0875\n",
      "Epoch 37/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0893 - val_loss: 0.0868\n",
      "Epoch 38/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0887 - val_loss: 0.0862\n",
      "Epoch 39/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0881 - val_loss: 0.0856\n",
      "Epoch 40/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0875 - val_loss: 0.0850\n",
      "Epoch 41/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0869 - val_loss: 0.0844\n",
      "Epoch 42/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0864 - val_loss: 0.0839\n",
      "Epoch 43/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0859 - val_loss: 0.0834\n",
      "Epoch 44/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0854 - val_loss: 0.0830\n",
      "Epoch 45/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0850 - val_loss: 0.0825\n",
      "Epoch 46/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0846 - val_loss: 0.0821\n",
      "Epoch 47/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0841 - val_loss: 0.0817\n",
      "Epoch 48/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0838 - val_loss: 0.0813\n",
      "Epoch 49/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0834 - val_loss: 0.0809\n",
      "Epoch 50/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0830 - val_loss: 0.0806\n",
      "Epoch 51/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0827 - val_loss: 0.0802\n",
      "Epoch 52/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0824 - val_loss: 0.0799\n",
      "Epoch 53/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0820 - val_loss: 0.0796\n",
      "Epoch 54/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0817 - val_loss: 0.0792\n",
      "Epoch 55/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0814 - val_loss: 0.0789\n",
      "Epoch 56/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0811 - val_loss: 0.0786\n",
      "Epoch 57/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0808 - val_loss: 0.0783\n",
      "Epoch 58/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0805 - val_loss: 0.0780\n",
      "Epoch 59/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0802 - val_loss: 0.0777\n",
      "Epoch 60/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0800 - val_loss: 0.0774\n",
      "Epoch 61/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0797 - val_loss: 0.0772\n",
      "Epoch 62/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0794 - val_loss: 0.0769\n",
      "Epoch 63/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0791 - val_loss: 0.0766\n",
      "Epoch 64/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0789 - val_loss: 0.0764\n",
      "Epoch 65/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0786 - val_loss: 0.0762\n",
      "Epoch 66/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0784 - val_loss: 0.0758\n",
      "Epoch 67/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0781 - val_loss: 0.0756\n",
      "Epoch 68/200\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0779 - val_loss: 0.0753\n",
      "Epoch 69/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0776 - val_loss: 0.0750\n",
      "Epoch 70/200\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0773 - val_loss: 0.0747\n",
      "Epoch 71/200\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0770 - val_loss: 0.0744\n",
      "Epoch 72/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0767 - val_loss: 0.0741\n",
      "Epoch 73/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0764 - val_loss: 0.0738\n",
      "Epoch 74/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0760 - val_loss: 0.0735\n",
      "Epoch 75/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0757 - val_loss: 0.0732\n",
      "Epoch 76/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0755 - val_loss: 0.0730\n",
      "Epoch 77/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0752 - val_loss: 0.0729\n",
      "Epoch 78/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0750 - val_loss: 0.0725\n",
      "Epoch 79/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0747 - val_loss: 0.0722\n",
      "Epoch 80/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0745 - val_loss: 0.0719\n",
      "Epoch 81/200\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0742 - val_loss: 0.0718\n",
      "Epoch 82/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0740 - val_loss: 0.0715\n",
      "Epoch 83/200\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0739 - val_loss: 0.0714\n",
      "Epoch 84/200\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0737 - val_loss: 0.0712\n",
      "Epoch 85/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0735 - val_loss: 0.0711\n",
      "Epoch 86/200\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0733 - val_loss: 0.0708\n",
      "Epoch 87/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0732 - val_loss: 0.0707\n",
      "Epoch 88/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0730 - val_loss: 0.0705\n",
      "Epoch 89/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0728 - val_loss: 0.0704\n",
      "Epoch 90/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0727 - val_loss: 0.0703\n",
      "Epoch 91/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0725 - val_loss: 0.0701\n",
      "Epoch 92/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0724 - val_loss: 0.0700\n",
      "Epoch 93/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0723 - val_loss: 0.0699\n",
      "Epoch 94/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0722 - val_loss: 0.0697\n",
      "Epoch 95/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0721 - val_loss: 0.0696\n",
      "Epoch 96/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0719 - val_loss: 0.0695\n",
      "Epoch 97/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0718 - val_loss: 0.0695\n",
      "Epoch 98/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0717 - val_loss: 0.0693\n",
      "Epoch 99/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0716 - val_loss: 0.0691\n",
      "Epoch 100/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0715 - val_loss: 0.0691\n",
      "Epoch 101/200\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0714 - val_loss: 0.0690\n",
      "Epoch 102/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0712 - val_loss: 0.0689\n",
      "Epoch 103/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0711 - val_loss: 0.0688\n",
      "Epoch 104/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0710 - val_loss: 0.0687\n",
      "Epoch 105/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0709 - val_loss: 0.0687\n",
      "Epoch 106/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0708 - val_loss: 0.0685\n",
      "Epoch 107/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0708 - val_loss: 0.0685\n",
      "Epoch 108/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0707 - val_loss: 0.0685\n",
      "Epoch 109/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0706 - val_loss: 0.0684\n",
      "Epoch 110/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0705 - val_loss: 0.0683\n",
      "Epoch 111/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0705 - val_loss: 0.0683\n",
      "Epoch 112/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0703 - val_loss: 0.0681\n",
      "Epoch 113/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0702 - val_loss: 0.0680\n",
      "Epoch 114/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0701 - val_loss: 0.0679\n"
     ]
    }
   ],
   "source": [
    "#Training the model with the real train data\n",
    "ts_real = RNN_regression(12)\n",
    "early_stopping = EarlyStopping(monitor='val_loss',patience=10,min_delta=0.001)\n",
    "\n",
    "real_train = ts_real.fit(x=X_real_train,\n",
    "                          y=y_real_train,\n",
    "                          validation_data=(X_real_test, y_real_test),\n",
    "                          epochs=200,\n",
    "                          batch_size=128,\n",
    "                          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 2s 47ms/step - loss: 0.4039 - val_loss: 0.3835\n",
      "Epoch 2/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3867 - val_loss: 0.3713\n",
      "Epoch 3/200\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3654 - val_loss: 0.3577\n",
      "Epoch 4/200\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3339 - val_loss: 0.3383\n",
      "Epoch 5/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2873 - val_loss: 0.3091\n",
      "Epoch 6/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2344 - val_loss: 0.2752\n",
      "Epoch 7/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1890 - val_loss: 0.2497\n",
      "Epoch 8/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1561 - val_loss: 0.2325\n",
      "Epoch 9/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1324 - val_loss: 0.2199\n",
      "Epoch 10/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1140 - val_loss: 0.2105\n",
      "Epoch 11/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1005 - val_loss: 0.2034\n",
      "Epoch 12/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0905 - val_loss: 0.1983\n",
      "Epoch 13/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0825 - val_loss: 0.1947\n",
      "Epoch 14/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0765 - val_loss: 0.1918\n",
      "Epoch 15/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0718 - val_loss: 0.1895\n",
      "Epoch 16/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0677 - val_loss: 0.1874\n",
      "Epoch 17/200\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0640 - val_loss: 0.1855\n",
      "Epoch 18/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0609 - val_loss: 0.1843\n",
      "Epoch 19/200\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0581 - val_loss: 0.1834\n",
      "Epoch 20/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0557 - val_loss: 0.1825\n",
      "Epoch 21/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0536 - val_loss: 0.1811\n",
      "Epoch 22/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0518 - val_loss: 0.1796\n",
      "Epoch 23/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0503 - val_loss: 0.1776\n",
      "Epoch 24/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0490 - val_loss: 0.1756\n",
      "Epoch 25/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0477 - val_loss: 0.1764\n",
      "Epoch 26/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0466 - val_loss: 0.1760\n",
      "Epoch 27/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0456 - val_loss: 0.1767\n",
      "Epoch 28/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0446 - val_loss: 0.1769\n",
      "Epoch 29/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0437 - val_loss: 0.1761\n",
      "Epoch 30/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0429 - val_loss: 0.1761\n",
      "Epoch 31/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0421 - val_loss: 0.1742\n",
      "Epoch 32/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0413 - val_loss: 0.1740\n",
      "Epoch 33/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0406 - val_loss: 0.1734\n",
      "Epoch 34/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0399 - val_loss: 0.1725\n",
      "Epoch 35/200\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0392 - val_loss: 0.1716\n",
      "Epoch 36/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0386 - val_loss: 0.1710\n",
      "Epoch 37/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0380 - val_loss: 0.1702\n",
      "Epoch 38/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0374 - val_loss: 0.1694\n",
      "Epoch 39/200\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0369 - val_loss: 0.1680\n",
      "Epoch 40/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0363 - val_loss: 0.1667\n",
      "Epoch 41/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0358 - val_loss: 0.1657\n",
      "Epoch 42/200\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0354 - val_loss: 0.1643\n",
      "Epoch 43/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0349 - val_loss: 0.1628\n",
      "Epoch 44/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0345 - val_loss: 0.1616\n",
      "Epoch 45/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0341 - val_loss: 0.1604\n",
      "Epoch 46/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0337 - val_loss: 0.1592\n",
      "Epoch 47/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0333 - val_loss: 0.1580\n",
      "Epoch 48/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0329 - val_loss: 0.1569\n",
      "Epoch 49/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0326 - val_loss: 0.1560\n",
      "Epoch 50/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0322 - val_loss: 0.1549\n",
      "Epoch 51/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0319 - val_loss: 0.1539\n",
      "Epoch 52/200\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0316 - val_loss: 0.1528\n",
      "Epoch 53/200\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0314 - val_loss: 0.1520\n",
      "Epoch 54/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0311 - val_loss: 0.1510\n",
      "Epoch 55/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0308 - val_loss: 0.1501\n",
      "Epoch 56/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0306 - val_loss: 0.1493\n",
      "Epoch 57/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0304 - val_loss: 0.1486\n",
      "Epoch 58/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0301 - val_loss: 0.1478\n",
      "Epoch 59/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0299 - val_loss: 0.1473\n",
      "Epoch 60/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0297 - val_loss: 0.1466\n",
      "Epoch 61/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0295 - val_loss: 0.1460\n",
      "Epoch 62/200\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0293 - val_loss: 0.1454\n",
      "Epoch 63/200\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0291 - val_loss: 0.1449\n",
      "Epoch 64/200\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0290 - val_loss: 0.1443\n",
      "Epoch 65/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0288 - val_loss: 0.1439\n",
      "Epoch 66/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0286 - val_loss: 0.1433\n",
      "Epoch 67/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0285 - val_loss: 0.1429\n",
      "Epoch 68/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0283 - val_loss: 0.1425\n",
      "Epoch 69/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0281 - val_loss: 0.1420\n",
      "Epoch 70/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0280 - val_loss: 0.1416\n",
      "Epoch 71/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0278 - val_loss: 0.1412\n",
      "Epoch 72/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0277 - val_loss: 0.1407\n",
      "Epoch 73/200\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0275 - val_loss: 0.1405\n",
      "Epoch 74/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0274 - val_loss: 0.1400\n",
      "Epoch 75/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0273 - val_loss: 0.1397\n",
      "Epoch 76/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0271 - val_loss: 0.1393\n",
      "Epoch 77/200\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0270 - val_loss: 0.1390\n",
      "Epoch 78/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0268 - val_loss: 0.1387\n",
      "Epoch 79/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0267 - val_loss: 0.1384\n",
      "Epoch 80/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0266 - val_loss: 0.1380\n",
      "Epoch 81/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0264 - val_loss: 0.1378\n",
      "Epoch 82/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0263 - val_loss: 0.1374\n",
      "Epoch 83/200\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0262 - val_loss: 0.1372\n",
      "Epoch 84/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0261 - val_loss: 0.1369\n",
      "Epoch 85/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0259 - val_loss: 0.1365\n",
      "Epoch 86/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0258 - val_loss: 0.1363\n",
      "Epoch 87/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0257 - val_loss: 0.1361\n",
      "Epoch 88/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0256 - val_loss: 0.1358\n",
      "Epoch 89/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0255 - val_loss: 0.1357\n",
      "Epoch 90/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0253 - val_loss: 0.1354\n",
      "Epoch 91/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0252 - val_loss: 0.1352\n",
      "Epoch 92/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0251 - val_loss: 0.1350\n",
      "Epoch 93/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0250 - val_loss: 0.1349\n",
      "Epoch 94/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0249 - val_loss: 0.1345\n",
      "Epoch 95/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0247 - val_loss: 0.1344\n",
      "Epoch 96/200\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0246 - val_loss: 0.1342\n",
      "Epoch 97/200\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0245 - val_loss: 0.1340\n",
      "Epoch 98/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0244 - val_loss: 0.1339\n",
      "Epoch 99/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0243 - val_loss: 0.1337\n",
      "Epoch 100/200\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0242 - val_loss: 0.1336\n",
      "Epoch 101/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0240 - val_loss: 0.1333\n",
      "Epoch 102/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0239 - val_loss: 0.1333\n",
      "Epoch 103/200\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0238 - val_loss: 0.1331\n",
      "Epoch 104/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0237 - val_loss: 0.1329\n",
      "Epoch 105/200\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0235 - val_loss: 0.1328\n",
      "Epoch 106/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0234 - val_loss: 0.1327\n",
      "Epoch 107/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0233 - val_loss: 0.1326\n",
      "Epoch 108/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0231 - val_loss: 0.1324\n",
      "Epoch 109/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0230 - val_loss: 0.1322\n",
      "Epoch 110/200\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0228 - val_loss: 0.1322\n",
      "Epoch 111/200\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0227 - val_loss: 0.1321\n",
      "Epoch 112/200\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0225 - val_loss: 0.1319\n",
      "Epoch 113/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0224 - val_loss: 0.1319\n",
      "Epoch 114/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0222 - val_loss: 0.1317\n",
      "Epoch 115/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0221 - val_loss: 0.1316\n",
      "Epoch 116/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0219 - val_loss: 0.1314\n",
      "Epoch 117/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0217 - val_loss: 0.1314\n",
      "Epoch 118/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0215 - val_loss: 0.1313\n",
      "Epoch 119/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0214 - val_loss: 0.1312\n",
      "Epoch 120/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0212 - val_loss: 0.1310\n",
      "Epoch 121/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0210 - val_loss: 0.1308\n",
      "Epoch 122/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0208 - val_loss: 0.1307\n",
      "Epoch 123/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0207 - val_loss: 0.1305\n",
      "Epoch 124/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0205 - val_loss: 0.1303\n",
      "Epoch 125/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0204 - val_loss: 0.1302\n",
      "Epoch 126/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0202 - val_loss: 0.1301\n",
      "Epoch 127/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0200 - val_loss: 0.1299\n",
      "Epoch 128/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0199 - val_loss: 0.1298\n",
      "Epoch 129/200\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0198 - val_loss: 0.1295\n",
      "Epoch 130/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0196 - val_loss: 0.1294\n",
      "Epoch 131/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0195 - val_loss: 0.1292\n",
      "Epoch 132/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0194 - val_loss: 0.1291\n",
      "Epoch 133/200\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0192 - val_loss: 0.1290\n",
      "Epoch 134/200\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0191 - val_loss: 0.1288\n",
      "Epoch 135/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0190 - val_loss: 0.1286\n",
      "Epoch 136/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0189 - val_loss: 0.1286\n",
      "Epoch 137/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0188 - val_loss: 0.1284\n",
      "Epoch 138/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0187 - val_loss: 0.1283\n",
      "Epoch 139/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0186 - val_loss: 0.1280\n",
      "Epoch 140/200\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0185 - val_loss: 0.1281\n",
      "Epoch 141/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0184 - val_loss: 0.1279\n",
      "Epoch 142/200\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0184 - val_loss: 0.1277\n",
      "Epoch 143/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0183 - val_loss: 0.1276\n",
      "Epoch 144/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0182 - val_loss: 0.1276\n",
      "Epoch 145/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0181 - val_loss: 0.1275\n",
      "Epoch 146/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0180 - val_loss: 0.1274\n",
      "Epoch 147/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0180 - val_loss: 0.1272\n",
      "Epoch 148/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0179 - val_loss: 0.1272\n",
      "Epoch 149/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0178 - val_loss: 0.1271\n",
      "Epoch 150/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0177 - val_loss: 0.1270\n",
      "Epoch 151/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0177 - val_loss: 0.1269\n",
      "Epoch 152/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0176 - val_loss: 0.1268\n",
      "Epoch 153/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0176 - val_loss: 0.1267\n",
      "Epoch 154/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0175 - val_loss: 0.1266\n",
      "Epoch 155/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0175 - val_loss: 0.1266\n",
      "Epoch 156/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0174 - val_loss: 0.1265\n",
      "Epoch 157/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0174 - val_loss: 0.1264\n",
      "Epoch 158/200\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0173 - val_loss: 0.1264\n",
      "Epoch 159/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0173 - val_loss: 0.1263\n",
      "Epoch 160/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0172 - val_loss: 0.1263\n",
      "Epoch 161/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0172 - val_loss: 0.1263\n"
     ]
    }
   ],
   "source": [
    "#Training the model with the synthetic data\n",
    "ts_synth = RNN_regression(12)\n",
    "early_stopping = EarlyStopping(monitor='val_loss',patience=10,min_delta=0.001)\n",
    "synth_train = ts_synth.fit(x=X_synth_train,\n",
    "                          y=y_synth_train,\n",
    "                          validation_data=(X_real_test, y_real_test),\n",
    "                          epochs=200,\n",
    "                          batch_size=128,\n",
    "                          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 7ms/step\n",
      "19/19 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Real</th>\n",
       "      <td>0.365571</td>\n",
       "      <td>0.078726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synthetic</th>\n",
       "      <td>0.877522</td>\n",
       "      <td>0.009401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 r2       MAE\n",
       "Real       0.365571  0.078726\n",
       "Synthetic  0.877522  0.009401"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summarize the metrics here as a pandas dataframe\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_log_error\n",
    "real_predictions = ts_real.predict(X_real_test)\n",
    "synth_predictions = ts_synth.predict(X_real_test)\n",
    "\n",
    "\"\"\" metrics_dict = {'r2': [r2_score(y_real_test, real_predictions),\n",
    "                       r2_score(y_real_test, synth_predictions)],\n",
    "                'MAE': [mean_absolute_error(y_real_test, real_predictions),\n",
    "                        mean_absolute_error(y_real_test, synth_predictions)],\n",
    "                'MRLE': [mean_squared_log_error(y_real_test, real_predictions),\n",
    "                         mean_squared_log_error(y_real_test, synth_predictions)]} \"\"\"\n",
    "metrics_dict = {'r2': [r2_score(real_data[train_idx, -1, 0:14], real_data[train_idx, -2, 0:14]),\n",
    "                       r2_score(synth_data[train_idx, -1, 0:14], synth_data[train_idx, -2, 0:14])],\n",
    "                'MAE': [mean_absolute_error(real_data[train_idx, -1, 0:14], real_data[train_idx, -2, 0:14]),\n",
    "                        mean_absolute_error(synth_data[train_idx, -1, 0:14], synth_data[train_idx, -2, 0:14])]}\n",
    "\n",
    "\n",
    "\n",
    "results = pd.DataFrame(metrics_dict, index=['Real', 'Synthetic'])\n",
    "\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ydata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
